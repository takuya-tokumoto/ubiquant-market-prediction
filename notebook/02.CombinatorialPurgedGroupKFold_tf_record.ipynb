{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6d9a33-0a6a-4f69-a71c-fb8f1d51f672",
   "metadata": {},
   "source": [
    "データセット\n",
    "- https://www.kaggle.com/datasets/lonnieqin/ubiquant-market-prediction-half-precision-pickle\n",
    "\n",
    "\n",
    "サンプルコード\n",
    "- https://www.kaggle.com/code/lonnieqin/ump-tf-record-combinatorialpurgedgroupkfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83f4b2-8acb-4799-9e64-2abdbd036e2b",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7a0e84-a143-4898-855b-a1d3da9a667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f28e81-2200-4179-bc44-18dad13a210c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf91d5d6-c7f8-4864-9407-3be5b130d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorialPurgedGroupKFold():\n",
    "    def __init__(self, n_splits = 6, n_test_splits = 2, purge = 1, pctEmbargo = 0.01, **kwargs):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_test_splits = n_test_splits\n",
    "        self.purge = purge\n",
    "        self.pctEmbargo = pctEmbargo\n",
    "        \n",
    "    def split(self, X, y = None, groups = None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "            \n",
    "        u, ind = np.unique(groups, return_index = True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_groups = len(unique_groups)\n",
    "        group_dict = {}\n",
    "        for idx in range(len(X)):\n",
    "            if groups[idx] in group_dict:\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "                \n",
    "        n_folds = comb(self.n_splits, self.n_test_splits, exact = True)\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "            \n",
    "        mbrg = int(n_groups * self.pctEmbargo)\n",
    "        if mbrg < 0:\n",
    "            raise ValueError(\n",
    "                \"The number of 'embargoed' groups should not be negative\")\n",
    "        \n",
    "        split_dict = {}\n",
    "        group_test_size = n_groups // self.n_splits\n",
    "        for split in range(self.n_splits):\n",
    "            if split == self.n_splits - 1:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):].tolist()\n",
    "            else:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):int((split + 1) * group_test_size)].tolist()\n",
    "        \n",
    "        for test_splits in combinations(range(self.n_splits), self.n_test_splits):\n",
    "            test_groups = []\n",
    "            banned_groups = []\n",
    "            for split in test_splits:\n",
    "                test_groups += split_dict[split]\n",
    "                banned_groups += unique_groups[split_dict[split][0] - self.purge:split_dict[split][0]].tolist()\n",
    "                banned_groups += unique_groups[split_dict[split][-1] + 1:split_dict[split][-1] + self.purge + mbrg + 1].tolist()\n",
    "            train_groups = [i for i in unique_groups if (i not in banned_groups) and (i not in test_groups)]\n",
    "\n",
    "            train_idx = []\n",
    "            test_idx = []\n",
    "            for train_group in train_groups:\n",
    "                train_idx += group_dict[train_group]\n",
    "            for test_group in test_groups:\n",
    "                test_idx += group_dict[test_group]\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eaa797-f83e-4843-a3ca-a297a37e9c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Fold 0\n",
      "====================================================================================================\n",
      "Train indices: [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 52\n",
      "Test Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] Length: 12\n",
      "====================================================================================================\n",
      "Fold 1\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23] Length: 12\n",
      "====================================================================================================\n",
      "Fold 2\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35] Length: 12\n",
      "====================================================================================================\n",
      "Fold 3\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] Length: 12\n",
      "====================================================================================================\n",
      "Fold 4\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59] Length: 12\n",
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53] Length: 54\n",
      "Test Indices: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 10\n"
     ]
    }
   ],
   "source": [
    "n_splits = 6\n",
    "n_test_splits = 1\n",
    "elements = list(range(10 * (n_splits + n_test_splits)))\n",
    "groups = [element // n_splits for element in elements]\n",
    "data = pd.DataFrame({\"group\": groups, \"element\": elements})\n",
    "kfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\n",
    "for index, (train_indices, test_indices) in enumerate(kfold.split(data, groups=data[\"group\"])):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Fold {index}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Train indices:\", train_indices, \"Length:\", len(train_indices))\n",
    "    print(\"Test Indices:\", test_indices, \"Length:\", len(test_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b2e53-4544-41f9-824f-a885b9d0b347",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a8f9082-f0b1-4000-9113-b9b091935b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  data  notebook  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "! ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f55ddf7-01ed-4e77-9497-403ac774dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 345 ms, sys: 1.02 s, total: 1.37 s\n",
      "Wall time: 1.37 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investment_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932617</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>-0.402100</td>\n",
       "      <td>0.378418</td>\n",
       "      <td>-0.203979</td>\n",
       "      <td>-0.413574</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.095703</td>\n",
       "      <td>0.200073</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.086792</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-1.044922</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>-0.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811035</td>\n",
       "      <td>-0.514160</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>-0.616699</td>\n",
       "      <td>-0.194214</td>\n",
       "      <td>1.771484</td>\n",
       "      <td>1.427734</td>\n",
       "      <td>1.133789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.387695</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.929688</td>\n",
       "      <td>-0.974121</td>\n",
       "      <td>-0.343506</td>\n",
       "      <td>-0.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>0.615723</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>-0.607910</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>-1.083008</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>-1.125977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.551758</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>-1.060547</td>\n",
       "      <td>-0.219116</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.612305</td>\n",
       "      <td>-0.113953</td>\n",
       "      <td>0.243652</td>\n",
       "      <td>0.568848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.343750</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>-0.606445</td>\n",
       "      <td>-0.586914</td>\n",
       "      <td>-0.815918</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.299072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.266357</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.608887</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>-0.783203</td>\n",
       "      <td>1.151367</td>\n",
       "      <td>-0.773438</td>\n",
       "      <td>-1.064453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>-0.262939</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>-0.583496</td>\n",
       "      <td>-0.618164</td>\n",
       "      <td>-0.742676</td>\n",
       "      <td>-0.946777</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.741211</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.588379</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.753418</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>-0.737793</td>\n",
       "      <td>-0.531738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   investment_id  time_id       f_0       f_1       f_2       f_3       f_4  \\\n",
       "0              1        0  0.932617  0.113708 -0.402100  0.378418 -0.203979   \n",
       "1              2        0  0.811035 -0.514160  0.742188 -0.616699 -0.194214   \n",
       "2              6        0  0.394043  0.615723  0.567871 -0.607910  0.068909   \n",
       "3              7        0 -2.343750 -0.011871  1.875000 -0.606445 -0.586914   \n",
       "4              8        0  0.842285 -0.262939  2.330078 -0.583496 -0.618164   \n",
       "\n",
       "        f_5       f_6       f_7  ...     f_291     f_292     f_293     f_294  \\\n",
       "0 -0.413574  0.965820  1.230469  ... -1.095703  0.200073  0.819336  0.941406   \n",
       "1  1.771484  1.427734  1.133789  ...  0.912598 -0.734375  0.819336  0.941406   \n",
       "2 -1.083008  0.979492 -1.125977  ...  0.912598 -0.551758 -1.220703 -1.060547   \n",
       "3 -0.815918  0.778320  0.299072  ...  0.912598 -0.266357 -1.220703  0.941406   \n",
       "4 -0.742676 -0.946777  1.230469  ...  0.912598 -0.741211 -1.220703  0.941406   \n",
       "\n",
       "      f_295     f_296     f_297     f_298     f_299    target  \n",
       "0 -0.086792 -1.086914 -1.044922 -0.287598  0.321533 -0.300781  \n",
       "1 -0.387695 -1.086914 -0.929688 -0.974121 -0.343506 -0.231079  \n",
       "2 -0.219116 -1.086914 -0.612305 -0.113953  0.243652  0.568848  \n",
       "3 -0.608887  0.104919 -0.783203  1.151367 -0.773438 -1.064453  \n",
       "4 -0.588379  0.104919  0.753418  1.345703 -0.737793 -0.531738  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_features = 300\n",
    "features = [f'f_{i}' for i in range(n_features)]\n",
    "train = pd.read_pickle('../data/input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b37ac3-cdc4-4524-a4a9-7f34ea310440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "investment_id    3141410\n",
       "time_id          3141410\n",
       "f_0              3141410\n",
       "f_1              3141410\n",
       "f_2              3141410\n",
       "                  ...   \n",
       "f_296            3141410\n",
       "f_297            3141410\n",
       "f_298            3141410\n",
       "f_299            3141410\n",
       "target           3141410\n",
       "Length: 303, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40eabe9d-6104-4462-aabf-83057a2a9907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    6\n",
       "3    7\n",
       "4    8\n",
       "Name: investment_id, dtype: uint16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_id = train.pop(\"investment_id\")\n",
    "investment_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325acb40-e1ad-444b-afe5-968e2a7896bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_id = train.pop(\"time_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f286ef1-c90c-44d4-b0da-81ea429d3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.300781\n",
       "1   -0.231079\n",
       "2    0.568848\n",
       "3   -1.064453\n",
       "4   -0.531738\n",
       "Name: target, dtype: float16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.pop(\"target\")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0cce0f-7caa-4ce5-9aef-d720f0f951c3",
   "metadata": {},
   "source": [
    "# Create TF-Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bcff41e-03b8-41d1-983d-2d8fbe9a71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(i):\n",
    "    dic = {}\n",
    "    dic[f\"features\"] = tf.train.Feature(float_list=tf.train.FloatList(value=list(train.iloc[i])))\n",
    "    dic[\"time_id\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[time_id.iloc[i]]))\n",
    "    dic[\"investment_id\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[investment_id.iloc[i]]))\n",
    "    dic[\"target\"] = tf.train.Feature(float_list=tf.train.FloatList(value=[y.iloc[i]]))\n",
    "    record_bytes = tf.train.Example(features=tf.train.Features(feature=dic)).SerializeToString()\n",
    "    return record_bytes\n",
    "    \n",
    "def decode_function(record_bytes):\n",
    "  return tf.io.parse_single_example(\n",
    "      # Data\n",
    "      record_bytes,\n",
    "      # Schema\n",
    "      {\n",
    "          \"features\": tf.io.FixedLenFeature([300], dtype=tf.float32),\n",
    "          \"time_id\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "          \"investment_id\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "          \"target\": tf.io.FixedLenFeature([], dtype=tf.float32)\n",
    "      }\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03bb9b-6f0c-4890-905f-65aeae0c6511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train Sample size: 2567952\n",
      "Test Sample size: 544192\n",
      "Creating fold_0_train.tfrecords\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "n_splits = 5\n",
    "n_test_splits = 1\n",
    "kfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\n",
    "for fold, (train_indices, test_indices) in enumerate(kfold.split(train, groups=time_id)):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Fold {index}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Train Sample size:\", len(train_indices))\n",
    "    print(\"Test Sample size:\", len(test_indices))\n",
    "    train_save_path = f\"fold_{fold}_train.tfrecords\"\n",
    "    begin = time.time()\n",
    "    print(f\"Creating {train_save_path}\")\n",
    "    with tf.io.TFRecordWriter(train_save_path) as file_writer:\n",
    "        for i in train_indices:\n",
    "            file_writer.write(create_record(i))\n",
    "    print(\"Elapsed time: %.2f\"%(time.time() - begin))\n",
    "    begin = time.time()\n",
    "    print(f\"Creating {train_save_path}\")\n",
    "    test_save_path = f\"fold_{fold}_test.tfrecords\"\n",
    "    with tf.io.TFRecordWriter(test_save_path) as file_writer:\n",
    "        for i in test_indices:\n",
    "            file_writer.write(create_record(i))\n",
    "    print(\"Elapsed time: %.2f\"%(time.time() - begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34a586-6139-4a79-9f63-d977acfa1987",
   "metadata": {},
   "source": [
    "## Write unique Investment Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5abef-e3a3-4354-a4ae-7a6a839c3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_ids = investment_id.unique()\n",
    "investment_id_df = pd.DataFrame({\"investment_id\": investment_ids})\n",
    "investment_id_df.to_csv(\"investment_ids.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
