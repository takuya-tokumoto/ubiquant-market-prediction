{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ecdb9c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031283f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from scipy import stats\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "### add random seed\n",
    "tf.random.set_seed(3)\n",
    "# tf.random.set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac067cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52575b11",
   "metadata": {},
   "source": [
    "# 読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49c132dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.43 s, sys: 7.25 s, total: 12.7 s\n",
      "Wall time: 8.63 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investment_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "      <td>0.378386</td>\n",
       "      <td>-0.203938</td>\n",
       "      <td>-0.413469</td>\n",
       "      <td>0.965623</td>\n",
       "      <td>1.230508</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>0.200075</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.086764</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-1.044826</td>\n",
       "      <td>-0.287605</td>\n",
       "      <td>0.321566</td>\n",
       "      <td>-0.300875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>-0.514115</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>-0.616673</td>\n",
       "      <td>-0.194255</td>\n",
       "      <td>1.771210</td>\n",
       "      <td>1.428127</td>\n",
       "      <td>1.134144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.734579</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.387617</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.929529</td>\n",
       "      <td>-0.974060</td>\n",
       "      <td>-0.343624</td>\n",
       "      <td>-0.231040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393974</td>\n",
       "      <td>0.615937</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>-0.607963</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>-1.083155</td>\n",
       "      <td>0.979656</td>\n",
       "      <td>-1.125681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.551904</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>-1.060166</td>\n",
       "      <td>-0.219097</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.612428</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.243608</td>\n",
       "      <td>0.568807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.343535</td>\n",
       "      <td>-0.011870</td>\n",
       "      <td>1.874606</td>\n",
       "      <td>-0.606346</td>\n",
       "      <td>-0.586827</td>\n",
       "      <td>-0.815737</td>\n",
       "      <td>0.778096</td>\n",
       "      <td>0.298990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.266359</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.609113</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>-0.783423</td>\n",
       "      <td>1.151730</td>\n",
       "      <td>-0.773309</td>\n",
       "      <td>-1.064780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>-0.262993</td>\n",
       "      <td>2.330030</td>\n",
       "      <td>-0.583422</td>\n",
       "      <td>-0.618392</td>\n",
       "      <td>-0.742814</td>\n",
       "      <td>-0.946789</td>\n",
       "      <td>1.230508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.588445</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>0.753279</td>\n",
       "      <td>1.345611</td>\n",
       "      <td>-0.737624</td>\n",
       "      <td>-0.531940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   investment_id  time_id       f_0       f_1       f_2       f_3       f_4  \\\n",
       "0              1        0  0.932573  0.113691 -0.402206  0.378386 -0.203938   \n",
       "1              2        0  0.810802 -0.514115  0.742368 -0.616673 -0.194255   \n",
       "2              6        0  0.393974  0.615937  0.567806 -0.607963  0.068883   \n",
       "3              7        0 -2.343535 -0.011870  1.874606 -0.606346 -0.586827   \n",
       "4              8        0  0.842057 -0.262993  2.330030 -0.583422 -0.618392   \n",
       "\n",
       "        f_5       f_6       f_7  ...     f_291     f_292     f_293     f_294  \\\n",
       "0 -0.413469  0.965623  1.230508  ... -1.095620  0.200075  0.819155  0.941183   \n",
       "1  1.771210  1.428127  1.134144  ...  0.912726 -0.734579  0.819155  0.941183   \n",
       "2 -1.083155  0.979656 -1.125681  ...  0.912726 -0.551904 -1.220772 -1.060166   \n",
       "3 -0.815737  0.778096  0.298990  ...  0.912726 -0.266359 -1.220772  0.941183   \n",
       "4 -0.742814 -0.946789  1.230508  ...  0.912726 -0.741355 -1.220772  0.941183   \n",
       "\n",
       "      f_295     f_296     f_297     f_298     f_299    target  \n",
       "0 -0.086764 -1.087009 -1.044826 -0.287605  0.321566 -0.300875  \n",
       "1 -0.387617 -1.087009 -0.929529 -0.974060 -0.343624 -0.231040  \n",
       "2 -0.219097 -1.087009 -0.612428 -0.113944  0.243608  0.568807  \n",
       "3 -0.609113  0.104928 -0.783423  1.151730 -0.773309 -1.064780  \n",
       "4 -0.588445  0.104928  0.753279  1.345611 -0.737624 -0.531940  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_features = 300\n",
    "features = [f'f_{i}' for i in range(n_features)]\n",
    "feature_columns = ['investment_id', 'time_id'] + features\n",
    "train = pd.read_parquet('../data/input/ubiquant-parquet/train_low_mem.parquet', columns=feature_columns + [\"target\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26aaf916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    6\n",
       "3    7\n",
       "4    8\n",
       "Name: investment_id, dtype: uint16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_id = train.pop(\"investment_id\")\n",
    "investment_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da85cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8be272cd",
   "metadata": {},
   "source": [
    "# 学習済みモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc718817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 14:01:53.260495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:\n",
      "2022-05-14 14:01:53.260532: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-14 14:01:53.260551: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-17-131): /proc/driver/nvidia/version does not exist\n",
      "2022-05-14 14:01:53.260800: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# investment_id入力層を定義\n",
    "\n",
    "# %%time\n",
    "investment_ids = list(investment_id.unique())\n",
    "investment_id_size = len(investment_ids) + 1\n",
    "investment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\n",
    "with tf.device(\"cpu\"):\n",
    "    investment_id_lookup_layer.adapt(investment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseモデル\n",
    "\n",
    "def get_model():\n",
    "    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n",
    "    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n",
    "    \n",
    "    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n",
    "    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n",
    "    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    \n",
    "    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n",
    "    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\"])\n",
    "    return model\n",
    "\n",
    "# CNN2Dモデル\n",
    "def get_model_cnn2d():\n",
    "    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n",
    "    \n",
    "    ## Dense 1 ##\n",
    "    feature_x = layers.Dense(256, activation='swish', kernel_initializer = 'he_normal')(features_inputs)\n",
    "    feature_x = layers.Dropout(0.1)(feature_x)\n",
    "#     ## Dense 2 ##\n",
    "#     feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "#     feature_x = layers.Dropout(0.1)(feature_x)\n",
    "    ## convolution 1 ##\n",
    "    feature_x = layers.Reshape((-1,1))(feature_x)\n",
    "    feature_x = layers.Conv1D(filters=16, kernel_size=4, strides=1, padding='same', kernel_initializer = 'he_normal')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU(0.5)(feature_x)\n",
    "    ## convolution 2 ##\n",
    "    feature_x = layers.Conv1D(filters=16, kernel_size=4, strides=4, padding='same', kernel_initializer = 'he_normal')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU(0.5)(feature_x)\n",
    "    ## convolution 3 ##\n",
    "    feature_x = layers.Conv1D(filters=64, kernel_size=4, strides=1, padding='same', kernel_initializer = 'he_normal')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU(0.5)(feature_x)\n",
    "\n",
    "    ## convolution2D 1 ##\n",
    "    feature_x = layers.Reshape((64,64,1))(feature_x)\n",
    "    feature_x = layers.Conv2D(filters=32, kernel_size=4, strides=1, padding='same', kernel_initializer = 'he_normal')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU(0.5)(feature_x)\n",
    "    ## convolution2D 2 ##\n",
    "    feature_x = layers.Conv2D(filters=32, kernel_size=4, strides=4, padding='same', kernel_initializer = 'he_normal')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU(0.5)(feature_x)\n",
    "    ## convolution2D 3 ##\n",
    "    feature_x = layers.Conv2D(filters=32, kernel_size=4, strides=4, padding='same', kernel_initializer = 'he_normal')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU(0.5)(feature_x)\n",
    "\n",
    "    ## flatten ##\n",
    "    feature_x = layers.Flatten()(feature_x)\n",
    "    ## Dense 3 ##\n",
    "    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\", kernel_initializer = 'he_normal')(feature_x)\n",
    "    ## Dense 4 ##\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    ## Dense 5 ##    \n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\", kernel_initializer = 'he_normal')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    ## Dense 6 ##\n",
    "    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\", kernel_initializer = 'he_normal')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    ## Dense 7 ##\n",
    "    output = layers.Dense(1)(x)\n",
    "    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    model = tf.keras.Model(inputs=[features_inputs], outputs=[output])\n",
    "    \n",
    "    \n",
    "    learning_sch = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate = 0.001,\n",
    "        decay_steps = 9700,\n",
    "        decay_rate = 0.98\n",
    "    )\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate = learning_sch)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer = adam, loss='mse', metrics=['mse', \"mae\", \"mape\", \n",
    "#                                                          rmse, correlation\n",
    "                                                        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2701f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4529905",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ../data/model_wight/ump-prediction-with-conv2d-reluab/model_0.tf",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     10\u001b[0m     models_cnn2d \u001b[38;5;241m=\u001b[39m get_model_cnn2d()\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mmodels_cnn2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/model_wight/ump-prediction-with-conv2d-reluab/model_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     models_cnn2d\u001b[38;5;241m.\u001b[39mappend(model)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mUnimplementedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ../data/model_wight/ump-prediction-with-conv2d-reluab/model_0.tf"
     ]
    }
   ],
   "source": [
    "model_base = []\n",
    "\n",
    "# for i in range(5):\n",
    "#     model_base = get_model()\n",
    "#     model_base.load_weights(f'../data/model_wight/dnn-base-outputs/model_{i}')\n",
    "#     model_base.append(model)\n",
    "\n",
    "models_cnn2d = []\n",
    "for i in range(5):\n",
    "    models_cnn2d = get_model_cnn2d()\n",
    "    models_cnn2d.load_weights(f'../data/model_wight/ump-prediction-with-conv2d-reluab/model_{i}.tf')\n",
    "    models_cnn2d.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154d778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639c67dd",
   "metadata": {},
   "source": [
    "# スコアリング用マート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2c3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be12b1e",
   "metadata": {},
   "source": [
    "# スコアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2ecd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
