{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6d9a33-0a6a-4f69-a71c-fb8f1d51f672",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "データセット\n",
    "- ./data/input/ubiquant-market-prediction-half-precision-pickle/ に配置\n",
    "- https://www.kaggle.com/datasets/lonnieqin/ubiquant-market-prediction-half-precision-pickle\n",
    "\n",
    "\n",
    "サンプルコード\n",
    "- https://www.kaggle.com/code/lonnieqin/ump-tf-record-combinatorialpurgedgroupkfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83f4b2-8acb-4799-9e64-2abdbd036e2b",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7a0e84-a143-4898-855b-a1d3da9a667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 03:20:25.129102: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:\n",
      "2022-05-05 03:20:25.129133: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f28e81-2200-4179-bc44-18dad13a210c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f0898e4-78a4-428a-afe1-f496ae05c071",
   "metadata": {},
   "source": [
    "# Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf91d5d6-c7f8-4864-9407-3be5b130d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorialPurgedGroupKFold():\n",
    "    def __init__(self, n_splits = 6, n_test_splits = 2, purge = 1, pctEmbargo = 0.01, **kwargs):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_test_splits = n_test_splits\n",
    "        self.purge = purge\n",
    "        self.pctEmbargo = pctEmbargo\n",
    "        \n",
    "    def split(self, X, y = None, groups = None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "            \n",
    "        u, ind = np.unique(groups, return_index = True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_groups = len(unique_groups)\n",
    "        group_dict = {}\n",
    "        for idx in range(len(X)):\n",
    "            if groups[idx] in group_dict:\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "                \n",
    "        n_folds = comb(self.n_splits, self.n_test_splits, exact = True)\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "            \n",
    "        mbrg = int(n_groups * self.pctEmbargo)\n",
    "        if mbrg < 0:\n",
    "            raise ValueError(\n",
    "                \"The number of 'embargoed' groups should not be negative\")\n",
    "        \n",
    "        split_dict = {}\n",
    "        group_test_size = n_groups // self.n_splits\n",
    "        for split in range(self.n_splits):\n",
    "            if split == self.n_splits - 1:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):].tolist()\n",
    "            else:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):int((split + 1) * group_test_size)].tolist()\n",
    "        \n",
    "        for test_splits in combinations(range(self.n_splits), self.n_test_splits):\n",
    "            test_groups = []\n",
    "            banned_groups = []\n",
    "            for split in test_splits:\n",
    "                test_groups += split_dict[split]\n",
    "                banned_groups += unique_groups[split_dict[split][0] - self.purge:split_dict[split][0]].tolist()\n",
    "                banned_groups += unique_groups[split_dict[split][-1] + 1:split_dict[split][-1] + self.purge + mbrg + 1].tolist()\n",
    "            train_groups = [i for i in unique_groups if (i not in banned_groups) and (i not in test_groups)]\n",
    "\n",
    "            train_idx = []\n",
    "            test_idx = []\n",
    "            for train_group in train_groups:\n",
    "                train_idx += group_dict[train_group]\n",
    "            for test_group in test_groups:\n",
    "                test_idx += group_dict[test_group]\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c08dd-2300-48af-8b9b-30dc33fb7201",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eaa797-f83e-4843-a3ca-a297a37e9c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Fold 0\n",
      "====================================================================================================\n",
      "Train indices: [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 52\n",
      "Test Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] Length: 12\n",
      "====================================================================================================\n",
      "Fold 1\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23] Length: 12\n",
      "====================================================================================================\n",
      "Fold 2\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35] Length: 12\n",
      "====================================================================================================\n",
      "Fold 3\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] Length: 12\n",
      "====================================================================================================\n",
      "Fold 4\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59] Length: 12\n",
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53] Length: 54\n",
      "Test Indices: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 10\n"
     ]
    }
   ],
   "source": [
    "n_splits = 6\n",
    "n_test_splits = 1\n",
    "elements = list(range(10 * (n_splits + n_test_splits)))\n",
    "groups = [element // n_splits for element in elements]\n",
    "data = pd.DataFrame({\"group\": groups, \"element\": elements})\n",
    "kfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\n",
    "for index, (train_indices, test_indices) in enumerate(kfold.split(data, groups=data[\"group\"])):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Fold {index}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Train indices:\", train_indices, \"Length:\", len(train_indices))\n",
    "    print(\"Test Indices:\", test_indices, \"Length:\", len(test_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab8d52-4f74-4ddb-8a73-3e54b996d6e9",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b2e53-4544-41f9-824f-a885b9d0b347",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f55ddf7-01ed-4e77-9497-403ac774dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.97 s, sys: 8.73 s, total: 15.7 s\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.300875</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "      <td>0.378386</td>\n",
       "      <td>-0.203938</td>\n",
       "      <td>-0.413469</td>\n",
       "      <td>0.965623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366028</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>0.200075</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.086764</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-1.044826</td>\n",
       "      <td>-0.287605</td>\n",
       "      <td>0.321566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.231040</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>-0.514115</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>-0.616673</td>\n",
       "      <td>-0.194255</td>\n",
       "      <td>1.771210</td>\n",
       "      <td>1.428127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154193</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.734579</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.387617</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.929529</td>\n",
       "      <td>-0.974060</td>\n",
       "      <td>-0.343624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.393974</td>\n",
       "      <td>0.615937</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>-0.607963</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>-1.083155</td>\n",
       "      <td>0.979656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138020</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.551904</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>-1.060166</td>\n",
       "      <td>-0.219097</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.612428</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.243608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.064780</td>\n",
       "      <td>-2.343535</td>\n",
       "      <td>-0.011870</td>\n",
       "      <td>1.874606</td>\n",
       "      <td>-0.606346</td>\n",
       "      <td>-0.586827</td>\n",
       "      <td>-0.815737</td>\n",
       "      <td>0.778096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382201</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.266359</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.609113</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>-0.783423</td>\n",
       "      <td>1.151730</td>\n",
       "      <td>-0.773309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.531940</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>-0.262993</td>\n",
       "      <td>2.330030</td>\n",
       "      <td>-0.583422</td>\n",
       "      <td>-0.618392</td>\n",
       "      <td>-0.742814</td>\n",
       "      <td>-0.946789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170365</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.588445</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>0.753279</td>\n",
       "      <td>1.345611</td>\n",
       "      <td>-0.737624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  investment_id    target       f_0       f_1       f_2       f_3  \\\n",
       "0        0              1 -0.300875  0.932573  0.113691 -0.402206  0.378386   \n",
       "1        0              2 -0.231040  0.810802 -0.514115  0.742368 -0.616673   \n",
       "2        0              6  0.568807  0.393974  0.615937  0.567806 -0.607963   \n",
       "3        0              7 -1.064780 -2.343535 -0.011870  1.874606 -0.606346   \n",
       "4        0              8 -0.531940  0.842057 -0.262993  2.330030 -0.583422   \n",
       "\n",
       "        f_4       f_5       f_6  ...     f_290     f_291     f_292     f_293  \\\n",
       "0 -0.203938 -0.413469  0.965623  ...  0.366028 -1.095620  0.200075  0.819155   \n",
       "1 -0.194255  1.771210  1.428127  ... -0.154193  0.912726 -0.734579  0.819155   \n",
       "2  0.068883 -1.083155  0.979656  ... -0.138020  0.912726 -0.551904 -1.220772   \n",
       "3 -0.586827 -0.815737  0.778096  ...  0.382201  0.912726 -0.266359 -1.220772   \n",
       "4 -0.618392 -0.742814 -0.946789  ... -0.170365  0.912726 -0.741355 -1.220772   \n",
       "\n",
       "      f_294     f_295     f_296     f_297     f_298     f_299  \n",
       "0  0.941183 -0.086764 -1.087009 -1.044826 -0.287605  0.321566  \n",
       "1  0.941183 -0.387617 -1.087009 -0.929529 -0.974060 -0.343624  \n",
       "2 -1.060166 -0.219097 -1.087009 -0.612428 -0.113944  0.243608  \n",
       "3  0.941183 -0.609113  0.104928 -0.783423  1.151730 -0.773309  \n",
       "4  0.941183 -0.588445  0.104928  0.753279  1.345611 -0.737624  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_features = 300\n",
    "features = [f'f_{i}' for i in range(n_features)]\n",
    "# train = pd.read_pickle('../data/input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\n",
    "train = pd.read_parquet('../data/input/ubiquant-market-prediction-half-precision-pickle/train_low_mem.parquet').drop([\"row_id\"], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5b37ac3-cdc4-4524-a4a9-7f34ea310440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_id          3141410\n",
       "investment_id    3141410\n",
       "target           3141410\n",
       "f_0              3141410\n",
       "f_1              3141410\n",
       "                  ...   \n",
       "f_295            3141410\n",
       "f_296            3141410\n",
       "f_297            3141410\n",
       "f_298            3141410\n",
       "f_299            3141410\n",
       "Length: 303, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40eabe9d-6104-4462-aabf-83057a2a9907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    6\n",
       "3    7\n",
       "4    8\n",
       "Name: investment_id, dtype: uint16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_id = train.pop(\"investment_id\")\n",
    "investment_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "325acb40-e1ad-444b-afe5-968e2a7896bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_id = train.pop(\"time_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f286ef1-c90c-44d4-b0da-81ea429d3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.300875\n",
       "1   -0.231040\n",
       "2    0.568807\n",
       "3   -1.064780\n",
       "4   -0.531940\n",
       "Name: target, dtype: float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train.pop(\"target\")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0cce0f-7caa-4ce5-9aef-d720f0f951c3",
   "metadata": {},
   "source": [
    "## Create TF-Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bcff41e-03b8-41d1-983d-2d8fbe9a71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(i):\n",
    "    dic = {}\n",
    "    dic[f\"features\"] = tf.train.Feature(float_list=tf.train.FloatList(value=list(train.iloc[i])))\n",
    "    dic[\"time_id\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[time_id.iloc[i]]))\n",
    "    dic[\"investment_id\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[investment_id.iloc[i]]))\n",
    "    dic[\"target\"] = tf.train.Feature(float_list=tf.train.FloatList(value=[y.iloc[i]]))\n",
    "    record_bytes = tf.train.Example(features=tf.train.Features(feature=dic)).SerializeToString()\n",
    "    return record_bytes\n",
    "    \n",
    "def decode_function(record_bytes):\n",
    "  return tf.io.parse_single_example(\n",
    "      # Data\n",
    "      record_bytes,\n",
    "      # Schema\n",
    "      {\n",
    "          \"features\": tf.io.FixedLenFeature([300], dtype=tf.float32),\n",
    "          \"time_id\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "          \"investment_id\": tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "          \"target\": tf.io.FixedLenFeature([], dtype=tf.float32)\n",
    "      }\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c03bb9b-6f0c-4890-905f-65aeae0c6511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train Sample size: 2567952\n",
      "Test Sample size: 544192\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_0_train.tfrecords\n",
      "Elapsed time: 1269.88\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_0_train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [25:50, 1550.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 266.17\n",
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train Sample size: 2608404\n",
      "Test Sample size: 500873\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_1_train.tfrecords\n",
      "Elapsed time: 1256.12\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_1_train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [50:46, 1518.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 240.29\n",
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train Sample size: 2499599\n",
      "Test Sample size: 605976\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_2_train.tfrecords\n",
      "Elapsed time: 1209.28\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_2_train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [1:15:49, 1511.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 292.55\n",
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train Sample size: 2390442\n",
      "Test Sample size: 710108\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_3_train.tfrecords\n",
      "Elapsed time: 1149.68\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_3_train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [1:40:40, 1503.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 341.00\n",
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train Sample size: 2361149\n",
      "Test Sample size: 780261\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_4_train.tfrecords\n",
      "Elapsed time: 1150.17\n",
      "Creating ../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_4_train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [2:06:09, 1513.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 378.88\n",
      "CPU times: user 2h 5min 16s, sys: 51.9 s, total: 2h 6min 8s\n",
      "Wall time: 2h 6min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "n_splits = 5\n",
    "n_test_splits = 1\n",
    "kfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\n",
    "for fold, (train_indices, test_indices) in tqdm(enumerate(kfold.split(train, groups=time_id))):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Fold {index}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Train Sample size:\", len(train_indices))\n",
    "    print(\"Test Sample size:\", len(test_indices))\n",
    "    train_save_path = f\"../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_{fold}_train.tfrecords\"\n",
    "    begin = time.time()\n",
    "    print(f\"Creating {train_save_path}\")\n",
    "    with tf.io.TFRecordWriter(train_save_path) as file_writer:\n",
    "        for i in train_indices:\n",
    "            file_writer.write(create_record(i))\n",
    "    print(\"Elapsed time: %.2f\"%(time.time() - begin))\n",
    "    begin = time.time()\n",
    "    print(f\"Creating {train_save_path}\")\n",
    "    test_save_path = f\"../data/input/CombinatorialPurgedGroupKFold_tf_record/fold_{fold}_test.tfrecords\"\n",
    "    with tf.io.TFRecordWriter(test_save_path) as file_writer:\n",
    "        for i in test_indices:\n",
    "            file_writer.write(create_record(i))\n",
    "    print(\"Elapsed time: %.2f\"%(time.time() - begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34a586-6139-4a79-9f63-d977acfa1987",
   "metadata": {},
   "source": [
    "## Write unique Investment Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ec5abef-e3a3-4354-a4ae-7a6a839c3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_ids = investment_id.unique()\n",
    "investment_id_df = pd.DataFrame({\"investment_id\": investment_ids})\n",
    "investment_id_df.to_csv(\"../data/input/CombinatorialPurgedGroupKFold_tf_record/investment_ids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e57cdf-b7b3-4961-b4d0-eb518a17c814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
